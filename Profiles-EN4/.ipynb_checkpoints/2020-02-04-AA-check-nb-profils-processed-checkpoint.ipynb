{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## path for mdules\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "## imports\n",
    "\n",
    "import numpy as np\n",
    "import dask\n",
    "import xarray as xr\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import glob as glob\n",
    "import matplotlib.gridspec as gridspec\n",
    "import time\n",
    "from dask.diagnostics import ProgressBar\n",
    "from datetime import date\n",
    "import yaml\n",
    "import io\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(jsonfile,infos,prof,dsN,latN,lonN,timN,config,case,namezone):\n",
    "        ''' Make all the steps needed to create the final netcdf files for one profile\n",
    "        '''\n",
    "        list_profiles = infos.keys()\n",
    "        reference =  str(list(list_profiles)[prof])\n",
    "        print('Processing profile ', reference)\n",
    "        lat_prof = infos[list(list_profiles)[prof]]['latitude']\n",
    "        lon_prof = infos[list(list_profiles)[prof]]['longitude']\n",
    "        date_prof = infos[list(list_profiles)[prof]]['date']\n",
    "        file_prof = infos[list(list_profiles)[prof]]['file']\n",
    "        prof_prof = infos[list(list_profiles)[prof]]['profile no']\n",
    "\n",
    "        up=check_process_profile(file_prof,prof_prof,dsN,latN,lonN,timN)\n",
    "        \n",
    "        return up\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_model(config,case):\n",
    "        print('Opening data')\n",
    "        tfiles=\"/store/colombo/\"+config+\"/\"+config+\"-\"+case+\"-S/1d/2012/\"+config+\"-\"+case+\"_y20??m??d??.1d_gridT.nc\"\n",
    "\n",
    "        ##Open NATL60 files to get boundaries of domain\n",
    "\n",
    "        dsN = xr.open_mfdataset(tfiles,decode_times=False, chunks={'deptht':1 ,'time_counter':10})\n",
    "\n",
    "        latN = dsN.nav_lat\n",
    "        lonN = dsN.nav_lon\n",
    "        timN = dsN.time_counter\n",
    "        return dsN,latN,lonN,timN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prof_boundaries(dsN,latN,lonN,timN,lat_prof,lon_prof,date_prof):\n",
    "        ''' Check if the selected profile falls within model boundaries\n",
    "        '''\n",
    "\n",
    "        lamin=np.nanmin(latN.values)\n",
    "        lamax=np.nanmax(latN.values)\n",
    "        lomin=np.nanmin(lonN.values)\n",
    "        lomax=np.nanmax(lonN.values)\n",
    "\n",
    "        if (lamin < lat_prof < lamax) & (lomin < lon_prof < lomax) :\n",
    "                check=0.\n",
    "                print(\"selected profile falls within model boundaries, the program is proceeding\")\n",
    "        else:\n",
    "                check=1.\n",
    "                print(\"selected profile does not fall within model boundaries, the program is stopping\")\n",
    "        return check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_process_profile(fileEN4,ref_prof,dsN,latN,lonN,timN):\n",
    "        #select NATL60 data at the closest depth and within 0.25 and 15days near the location and date of the ARGO profile\n",
    "        diren4=\"/scratch/cnt0024/hmg2840/albert7a/EN4/\"\n",
    "        tfileEN4=diren4+fileEN4\n",
    "\n",
    "        dsen4=xr.open_dataset(tfileEN4)\n",
    "\n",
    "        laten4=dsen4['LATITUDE'][ref_prof]\n",
    "        lonen4=dsen4['LONGITUDE'][ref_prof]\n",
    "        depen4=dsen4['DEPH_CORRECTED'][ref_prof]\n",
    "        refen4=dsen4['DC_REFERENCE'][ref_prof]\n",
    "        dayen4=dsen4['JULD'][ref_prof]\n",
    "\n",
    "        observation_lon=lonen4\n",
    "        observation_lat=laten4\n",
    "        \n",
    "        #Coarse box in which EN4 profile is contained\n",
    "        step=1\n",
    "        indxBOX=np.where((lonN>observation_lon-1)&(lonN<observation_lon+1)&(latN>observation_lat-1)&(latN<observation_lat+1))\n",
    "        if len(indxBOX[0]) < 1:\n",
    "            print('profile is not really in the domain; exiting')\n",
    "            return 0\n",
    "        else:\n",
    "            up={str(refen4):{'reference':str(refen4.values),'file':fileEN4,'latitude':float(laten4.values),'longitude':float(lonen4.values),'date':str(dayen4.values)}}\n",
    "            return up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/02/20 15:03\n",
      "Opening data\n",
      "04/02/20 15:03\n",
      "dealing with profile A20121001-03180\n",
      "Processing profile  b' A20121001-03180'\n",
      "dealing with profile A20121001-03183\n",
      "Processing profile  b' A20121001-03183'\n",
      "dealing with profile A20121001-03275\n",
      "Processing profile  b' A20121001-03275'\n",
      "dealing with profile A20121001-03276\n",
      "Processing profile  b' A20121001-03276'\n"
     ]
    }
   ],
   "source": [
    "jsonfile = '/scratch/cnt0024/hmg2840/albert7a/EN4/profiles_files/NATL60-CJM165_EU_y2012-2013/NATL60-CJM165_EU_y2012-2013_1.json'\n",
    "dirn = '/scratch/cnt0024/hmg2840/albert7a/EN4/profiles_files/NATL60-CJM165_EU_y2012-2013/EU36-MPC001/'\n",
    "config = 'EU36'\n",
    "case = 'MPC001'\n",
    "namezone = 'NATL60-CJM165_EU_y2012-2013'\n",
    "\n",
    "sourcefile=open(jsonfile,'rU')\n",
    "infos=json.load(sourcefile)\n",
    "nb_profilesEN4=len(infos)\n",
    "\n",
    "print(time.strftime('%d/%m/%y %H:%M',time.localtime()))\n",
    "dsN,latN,lonN,timN = open_model(config,case)\n",
    "print(time.strftime('%d/%m/%y %H:%M',time.localtime()))\n",
    "\n",
    "for prof in np.arange(nb_profilesEN4):\n",
    "\n",
    "    list_profiles = infos.keys()\n",
    "    reference = str(list(list_profiles)[prof])\n",
    "    reference_profile=reference[-16:-1]\n",
    "    print(\"dealing with profile \"+reference_profile)\n",
    "\n",
    "    up=process(jsonfile,infos,prof,dsN,latN,lonN,timN,config,case,namezone)\n",
    "\n",
    "    if up == 0:\n",
    "        print('pas de prof')\n",
    "    else:\n",
    "        if 'dictyml' in locals():\n",
    "            dictyml.update(up)\n",
    "        else:\n",
    "            dictyml=up\n",
    "\n",
    "newjson='/scratch/cnt0024/hmg2840/albert7a/EN4/profiles_files/NATL60-CJM165_EU_y2012-2013/NATL60-CJM165_EU_y2012-2013_true_1.json'\n",
    "\n",
    " \n",
    "with io.open(newjson, 'w', encoding='utf8') as outfile:\n",
    "    outfile.write(str(json.dumps(dictyml, sort_keys=True,indent=4, separators=(',', ': '))))\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
