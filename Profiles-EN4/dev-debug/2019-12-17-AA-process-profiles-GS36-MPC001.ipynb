{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dask\n",
    "import xarray as xr\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import glob as glob\n",
    "import time\n",
    "from dask.diagnostics import ProgressBar\n",
    "from datetime import date\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(jsonfile,infos,prof,dsN,latN,lonN,timN):\n",
    "    ''' Make all the steps needed to create the final netcdf files for one profile\n",
    "    '''\n",
    "    list_profiles = infos.keys()\n",
    "    reference =  str(list(list_profiles)[prof])\n",
    "    print('Processing profile ', reference)\n",
    "    lat_prof = infos[list(list_profiles)[prof]]['latitude']\n",
    "    lon_prof = infos[list(list_profiles)[prof]]['longitude']\n",
    "    date_prof = infos[list(list_profiles)[prof]]['date']\n",
    "    file_prof = infos[list(list_profiles)[prof]]['file']\n",
    "    prof_prof = infos[list(list_profiles)[prof]]['profile no']\n",
    "\n",
    "    check=check_prof_GS36_boundaries(dsN,latN,lonN,timN,lat_prof,lon_prof,date_prof)\n",
    "    if check == 0.:\n",
    "        profil_temp_model_mean,profil_temp_model_percent10,profil_temp_model_percent90,profil_salt_model_mean,profil_salt_model_percent10,profil_salt_model_percent90,observation_dep,obsred_temp,obsred_salt,dep_level,model_dep,obsred_dep,observation_lat,observation_lon,observation_time = model_mean_percent_profile(file_prof,prof_prof,dsN,latN,lonN,timN)\n",
    "        create_netcdf_profile(jsonfile,reference,prof_prof,observation_lat,observation_lon,observation_time,profil_temp_model_mean,profil_temp_model_percent10,profil_temp_model_percent90,profil_salt_model_mean,profil_salt_model_percent10,profil_salt_model_percent90,observation_dep,obsred_temp,obsred_salt,dep_level,model_dep,obsred_dep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_gs36():\n",
    "    print('Opening GS36')\n",
    "    #NATL60\n",
    "    tfiles=\"/scratch/cnt0024/hmg2840/colombo/GS36/GS36-MPC001-S/1d/2012/GS36-MPC001_y20??m??d??.1d_gridT.nc\"\n",
    "\n",
    "    ##Open NATL60 files to get boundaries of domain\n",
    "\n",
    "    dsN = xr.open_mfdataset(tfiles,concat_dim='time_counter',decode_times=False, chunks={'deptht':1 ,'time_counter':10})\n",
    "\n",
    "    latN = dsN.nav_lat\n",
    "    lonN = dsN.nav_lon\n",
    "    timN = dsN.time_counter\n",
    "    return dsN,latN,lonN,timN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prof_GS36_boundaries(dsN,latN,lonN,timN,lat_prof,lon_prof,date_prof):\n",
    "    ''' Check if the selected profile falls within NATL60 boundaries\n",
    "    '''\n",
    "\n",
    "    lamin=np.nanmin(latN.values)\n",
    "    lamax=np.nanmax(latN.values)\n",
    "    lomin=np.nanmin(lonN.values)\n",
    "    lomax=np.nanmax(lonN.values)\n",
    "\n",
    "    if (lamin < lat_prof < lamax) & (lomin < lon_prof < lomax) :\n",
    "        check=0.\n",
    "        print(\"selected profile falls within GS36 boundaries, the program is proceeding\")\n",
    "    else:\n",
    "        check=1.\n",
    "        print(\"selected profile does not fall within GS36 boundaries, the program is stopping\")\n",
    "    return check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_mean_percent_profile(fileEN4,ref_prof,dsN,latN,lonN,timN):\n",
    "    #select NATL60 data at the closest depth and within 0.25 and 15days near the location and date of the ARGO profile\n",
    "    diren4=\"/scratch/cnt0024/hmg2840/albert7a/EN4/\"\n",
    "    tfileEN4=diren4+fileEN4\n",
    "\n",
    "    dsen4=xr.open_dataset(tfileEN4)\n",
    "\n",
    "    laten4=dsen4['LATITUDE'][ref_prof]\n",
    "    lonen4=dsen4['LONGITUDE'][ref_prof]\n",
    "    dayen4=dsen4['JULD'][ref_prof]\n",
    "\n",
    "    dateen4= pd.to_datetime(str(dayen4.values))\n",
    "    ten4 = datetime.datetime(int(dateen4.strftime('%Y')),int(dateen4.strftime('%m')),int(dateen4.strftime('%d')),int(dateen4.strftime('%H')),int(dateen4.strftime('%M')))\n",
    "    tsecen4=(ten4-datetime.datetime(1900,1,1,0,0)).total_seconds()\n",
    "\n",
    "    observation_lon=lonen4\n",
    "    observation_lat=laten4\n",
    "    observation_time=tsecen4\n",
    "\n",
    "    tempen4=dsen4['POTM_CORRECTED'][ref_prof]\n",
    "    salten4=dsen4['PSAL_CORRECTED'][ref_prof]\n",
    "    depen4=dsen4['DEPH_CORRECTED'][ref_prof]\n",
    "\n",
    "    observation_dep=depen4\n",
    "    observation_temp=tempen4\n",
    "    observation_salt=salten4\n",
    "\n",
    "    depN = dsN.deptht\n",
    "    tempN=dsN.votemper\n",
    "    saltN=dsN.vosaline\n",
    "\n",
    "    #get the number of useful levels in EN4 profile\n",
    "    dep_level=np.zeros(1)\n",
    "\n",
    "    for k in np.arange(len(observation_dep)):\n",
    "        if not np.isnan(observation_dep[k]):\n",
    "            dep_level[0]=k\n",
    "\n",
    "    #get the corresponding model level\n",
    "    model_level=np.zeros(int(dep_level[0]))\n",
    "    model_dep=np.zeros(int(dep_level[0]))\n",
    "    obsred_dep=np.zeros(int(dep_level[0]))\n",
    "    obsred_temp=np.zeros(int(dep_level[0]))\n",
    "    obsred_salt=np.zeros(int(dep_level[0]))\n",
    "    for z in np.arange(int(dep_level[0])):\n",
    "        obsred_dep[int(z)]=observation_dep[int(z)]\n",
    "        obsred_temp[int(z)]=observation_temp[int(z)]\n",
    "        obsred_salt[int(z)]=observation_salt[int(z)]\n",
    "        diff_dep=0*depN.values\n",
    "        for k in np.arange(len(depN.values)):\n",
    "            diff_dep[k]=depN.values[k]-obsred_dep[int(z)]\n",
    "        lev=np.where(np.abs(diff_dep)==np.min(np.abs(diff_dep)))\n",
    "        model_level[z]=lev[0]\n",
    "        model_dep[z]=depN.values[lev[0]]\n",
    "\n",
    "    #Coarse box in which EN4 profile is contained\n",
    "    step=1\n",
    "    indxBOX=np.where((lonN>observation_lon-1)&(lonN<observation_lon+1)&(latN>observation_lat-1)&(latN<observation_lat+1))\n",
    "    model_lonBOX=lonN[np.min(indxBOX[0]):np.max(indxBOX[0]):step,np.min(indxBOX[1]):np.max(indxBOX[1]):step]\n",
    "    model_latBOX=latN[np.min(indxBOX[0]):np.max(indxBOX[0]):step,np.min(indxBOX[1]):np.max(indxBOX[1]):step]\n",
    "    model_lonBOX_array=model_lonBOX.values\n",
    "    model_latBOX_array=model_latBOX.values\n",
    "    t01012013 = datetime.datetime(2013,1,1,0,0)\n",
    "    tsec01012013=(t01012013-datetime.datetime(1900,1,1,0,0)).total_seconds()\n",
    "    if tsecen4 > tsec01012013:\n",
    "        tsecen4=tsecen4-365*24*3600\n",
    "    else:\n",
    "        tsecen4=tsecen4\n",
    "    indtBOX=np.where((timN.values < tsecen4 + 15*24*3600) & (timN.values > tsecen4 - 15*24*3600) )\n",
    "    model_tBOX=timN[indtBOX[0][0]:indtBOX[0][-1]]\n",
    "    t_dim=np.arange(len(model_tBOX))\n",
    "    x_dim=np.arange(model_lonBOX_array.shape[1])\n",
    "    y_dim=np.arange(model_lonBOX_array.shape[0])\n",
    "\n",
    "    def profile_mean_percent(k):\n",
    "\n",
    "        #decoupage grossier autour de la position du profile ARGO pour un niveau vertical\n",
    "\n",
    "        model_tempBOX=tempN[indtBOX[0][0]:indtBOX[0][-1],k,np.min(indxBOX[0]):np.max(indxBOX[0]):step,np.min(indxBOX[1]):np.max(indxBOX[1]):step]\n",
    "        model_saltBOX=saltN[indtBOX[0][0]:indtBOX[0][-1],k,np.min(indxBOX[0]):np.max(indxBOX[0]):step,np.min(indxBOX[1]):np.max(indxBOX[1]):step]\n",
    "\n",
    "        model_tempBOX_array=model_tempBOX.values\n",
    "        model_saltBOX_array=model_saltBOX.values\n",
    "        model_tBOX_array=model_tBOX.values\n",
    "\n",
    "        # construction d'un nouveau xarray\n",
    "        d = {}\n",
    "        d['time_counter'] = ('time_counter',t_dim)\n",
    "        d['y'] = ('y',y_dim)\n",
    "        d['x'] = ('x',x_dim)\n",
    "        d['nav_lat'] = (['y','x'],model_latBOX_array)\n",
    "        d['nav_lon'] = (['y','x'],model_lonBOX_array)\n",
    "\n",
    "        d['votemper'] = (['time_counter','y','x'], model_tempBOX_array)\n",
    "        d['vosaline'] = (['time_counter','y','x'], model_saltBOX_array)\n",
    "        d['time_counter'] = (['time_counter'], model_tBOX_array)\n",
    "        dset = xr.Dataset(d)\n",
    "\n",
    "        latB = dset.nav_lat\n",
    "        lonB = dset.nav_lon\n",
    "        model_temperatureB = dset.votemper\n",
    "        model_salinityB = dset.vosaline\n",
    "        model_timeB = dset.time_counter\n",
    "\n",
    "        # selection plus fine des profils\n",
    "\n",
    "        lon_stacked = lonB.stack(profile=('x', 'y'))\n",
    "        lat_stacked = latB.stack(profile=('x', 'y'))\n",
    "\n",
    "        distance_threshold = 0.25\n",
    "        square_distance_to_observation = (lon_stacked - observation_lon)**2 + (lat_stacked-observation_lat)**2\n",
    "        is_close_to_observation = square_distance_to_observation < distance_threshold**2\n",
    "\n",
    "        model_temperature_stacked = model_temperatureB.stack(profile=('x', 'y'))\n",
    "        model_salinity_stacked = model_salinityB.stack(profile=('x', 'y'))\n",
    "\n",
    "        model_temperature_near_observation = model_temperature_stacked.where(is_close_to_observation,drop=True)\n",
    "        model_salinity_near_observation = model_salinity_stacked.where(is_close_to_observation, drop=True)\n",
    "        lat_near_observation = lat_stacked.where(is_close_to_observation, drop=True)\n",
    "        lon_near_observation = lon_stacked.where(is_close_to_observation, drop=True)\n",
    "\n",
    "        model_temp_dask=dask.array.from_array(model_temperature_near_observation,chunks=(100,100))\n",
    "        model_temp_dask_concat=dask.array.concatenate(model_temp_dask)\n",
    "        model_salt_dask=dask.array.from_array(model_salinity_near_observation,chunks=(100,100))\n",
    "        model_salt_dask_concat=dask.array.concatenate(model_salt_dask)\n",
    "        temp_model_mean = model_temp_dask_concat.mean().compute()\n",
    "        temp_percentile_10= np.percentile(model_temp_dask_concat,10)\n",
    "        temp_percentile_90= np.percentile(model_temp_dask_concat,90)\n",
    "        salt_model_mean = model_salt_dask_concat.mean().compute()\n",
    "        salt_percentile_10= np.percentile(model_salt_dask_concat,10)\n",
    "        salt_percentile_90= np.percentile(model_salt_dask_concat,90)\n",
    "\n",
    "        return lat_near_observation,lon_near_observation,temp_model_mean,temp_percentile_10,temp_percentile_90,salt_model_mean,salt_percentile_10,salt_percentile_90\n",
    "\n",
    "    profil_temp_model_mean=np.zeros(int(dep_level[0]))\n",
    "    profil_temp_model_percent10=np.zeros(int(dep_level[0]))\n",
    "    profil_temp_model_percent90=np.zeros(int(dep_level[0]))\n",
    "    profil_salt_model_mean=np.zeros(int(dep_level[0]))\n",
    "    profil_salt_model_percent10=np.zeros(int(dep_level[0]))\n",
    "    profil_salt_model_percent90=np.zeros(int(dep_level[0]))\n",
    "\n",
    "\n",
    "    for z in np.arange(dep_level[0]):\n",
    "        lat_near_observation,lon_near_observation,temp_model_mean,temp_percentile_10,temp_percentile_90,salt_model_mean,salt_percentile_10,salt_percentile_90=profile_mean_percent(int(model_level[int(z)]))\n",
    "        profil_temp_model_mean[int(z)]=temp_model_mean\n",
    "        profil_temp_model_percent10[int(z)]=temp_percentile_10\n",
    "        profil_temp_model_percent90[int(z)]=temp_percentile_90\n",
    "        profil_salt_model_mean[int(z)]=salt_model_mean\n",
    "        profil_salt_model_percent10[int(z)]=salt_percentile_10\n",
    "        profil_salt_model_percent90[int(z)]=salt_percentile_90\n",
    "\n",
    "    return profil_temp_model_mean,profil_temp_model_percent10,profil_temp_model_percent90,profil_salt_model_mean,profil_salt_model_percent10,profil_salt_model_percent90,observation_dep,obsred_temp,obsred_salt,dep_level,model_dep,obsred_dep,observation_lat,observation_lon,observation_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_netcdf_profile(jsonfile,reference,ref_prof,observation_lat,observation_lon,observation_time,profil_temp_model_mean,profil_temp_model_percent10,profil_temp_model_percent90,profil_salt_model_mean,profil_salt_model_percent10,profil_salt_model_percent90,observation_dep,obsred_temp,obsred_salt,dep_level,model_dep,obsred_dep,config,case):\n",
    "\n",
    "    reference_profile=reference[-16:-1]\n",
    "    namezone=jsonfile[0:-5]\n",
    "    dirname=\"/scratch/cnt0024/hmg2840/albert7a/EN4/profiles_files/\"+namezone\n",
    "    if not os.path.exists(dirname):\n",
    "        os.mkdir(dirname)\n",
    "    \n",
    "    outname=\"/scratch/cnt0024/hmg2840/albert7a/EN4/profiles_files/\"+namezone+\"/profiles_EN4-\"+reference_profile[1:]+\"_\"+config+\"-\"+case+\"_TS.nc\"\n",
    "    print('output file is '+outname)\n",
    "    dsout=Dataset(outname,'w')\n",
    "\n",
    "    today=date.today()\n",
    "    dsout.description = \"This file contains one profile of temperature and salinity from EN4 dataset and the mean and 10 and 90 percentile of NATL60-CJM165 data within a 0.25deg circle around the location of the profile and 15 days before and after it has been sampled. This file has been created \"+str(today.day)+\"/\"+str(today.month)+\"/\"+str(today.year)\n",
    "\n",
    "    depth=dsout.createDimension('depth',dep_level[0])\n",
    "    x=dsout.createDimension('x',1)\n",
    "    y=dsout.createDimension('y',1)\n",
    "    \n",
    "    lat = dsout.createVariable('latitude_profileEN4', 'f8', ('y','x'))\n",
    "    lat.standart_name=\"latitude_profileEN4\"\n",
    "    lat.long_name = \"Latitude of selected EN4 profile\" \n",
    "    lat.units = \"degrees_north\"\n",
    "\n",
    "    lon = dsout.createVariable('longitude_profileEN4', 'f8', ('y','x'))\n",
    "    lon.standart_name=\"longitude_profileEN4\"\n",
    "    lon.long_name = \"Longitude of selected EN4 profile\" \n",
    "    lon.units = \"degrees_east\"\n",
    "\n",
    "    time = dsout.createVariable('time_profileEN4', 'f8', ('y','x'))\n",
    "    time.standart_name=\"time_profileEN4\"\n",
    "    time.timeg_name = \"Time in seconds from 1-1-1958 of selected EN4 profile\" \n",
    "    time.units = \"seconds\"\n",
    "\n",
    "    depth_en4 = dsout.createVariable('depth_en4', 'f8', ('depth'),fill_value=0.)\n",
    "    depth_en4.units = \"m\" \n",
    "    depth_en4.valid_min = 0.\n",
    "    depth_en4.valid_max = 8000.\n",
    "    depth_en4.long_name = \"Depth\" \n",
    "\n",
    "    depth_model = dsout.createVariable('depth_model', 'f8', ('depth'),fill_value=0.)\n",
    "    depth_model.units = \"m\" \n",
    "    depth_model.valid_min = 0.\n",
    "    depth_model.valid_max = 8000.\n",
    "    depth_model.long_name = \"Depth\" \n",
    "\n",
    "    temp_en4 = dsout.createVariable('temp_profileEN4', 'f8', ('depth'),fill_value=0.)\n",
    "    temp_en4.units = \"degC\" \n",
    "    temp_en4.valid_min = -10.\n",
    "    temp_en4.valid_max = 40.\n",
    "    temp_en4.long_name = \"Temperature profile of the selected EN4 profile\" \n",
    "\n",
    "    salt_en4 = dsout.createVariable('salt_profileEN4', 'f8', ('depth'),fill_value=0.)\n",
    "    salt_en4.units = \"PSU\" \n",
    "    salt_en4.valid_min = 20.\n",
    "    salt_en4.valid_max = 40.\n",
    "    salt_en4.long_name = \"Salinity profile of the selected EN4 profile\" \n",
    "\n",
    "    mean_temp_model = dsout.createVariable('mean_temp_model', 'f8', ('depth'),fill_value=0.)\n",
    "    mean_temp_model.units = \"degC\" \n",
    "    mean_temp_model.valid_min = -10.\n",
    "    mean_temp_model.valid_max = 40.\n",
    "    mean_temp_model.long_name = \"Mean Temperature profile of the model\" \n",
    "\n",
    "    mean_salt_model = dsout.createVariable('mean_salt_model', 'f8', ('depth'),fill_value=0.)\n",
    "    mean_salt_model.units = \"PSU\" \n",
    "    mean_salt_model.valid_min = 20.\n",
    "    mean_salt_model.valid_max = 40.\n",
    "    mean_salt_model.long_name = \"Mean Salinity profile of the model\" \n",
    "\n",
    "    percent10_temp_model = dsout.createVariable('percent10_temp_model', 'f8', ('depth'),fill_value=0.)\n",
    "    percent10_temp_model.units = \"degC\" \n",
    "    percent10_temp_model.valid_min = -10.\n",
    "    percent10_temp_model.valid_max = 40.\n",
    "    percent10_temp_model.long_name = \"Percent 10 Temperature profile of the model\" \n",
    "\n",
    "    percent10_salt_model = dsout.createVariable('percent10_salt_model', 'f8', ('depth'),fill_value=0.)\n",
    "    percent10_salt_model.units = \"PSU\" \n",
    "    percent10_salt_model.valid_min = 20.\n",
    "    percent10_salt_model.valid_max = 40.\n",
    "    percent10_salt_model.long_name = \"Percent 10 Salinity profile of the model\" \n",
    "\n",
    "    percent90_temp_model = dsout.createVariable('percent90_temp_model', 'f8', ('depth'),fill_value=0.)\n",
    "    percent90_temp_model.units = \"degC\" \n",
    "    percent90_temp_model.valid_min = -90.\n",
    "    percent90_temp_model.valid_max = 40.\n",
    "    percent90_temp_model.long_name = \"Percent 90 Temperature profile of the model\" \n",
    "\n",
    "    percent90_salt_model = dsout.createVariable('percent90_salt_model', 'f8', ('depth'),fill_value=0.)\n",
    "    percent90_salt_model.units = \"PSU\" \n",
    "    percent90_salt_model.valid_min = 20.\n",
    "    percent90_salt_model.valid_max = 40.\n",
    "    percent90_salt_model.long_name = \"Percent 90 Salinity profile of the model\" \n",
    "\n",
    "\n",
    "    lat[:]=observation_lat\n",
    "    lon[:]=observation_lon\n",
    "    time[:]=observation_time\n",
    "    depth_en4[:]=obsred_dep\n",
    "    depth_model[:]=model_dep\n",
    "    temp_en4[:]=obsred_temp\n",
    "    salt_en4[:]=obsred_salt\n",
    "    mean_temp_model[:]=profil_temp_model_mean\n",
    "    mean_salt_model[:]=profil_salt_model_mean\n",
    "    percent10_temp_model[:]=profil_temp_model_percent10\n",
    "    percent10_salt_model[:]=profil_salt_model_percent10\n",
    "    percent90_temp_model[:]=profil_temp_model_percent90\n",
    "    percent90_salt_model[:]=profil_salt_model_percent90\n",
    "    dsout.close()  # close the new file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonfile='NATL60-CJM165_GS_y2012-2013.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/12/19 12:36\n",
      "Opening GS36\n",
      "19/12/19 12:38\n"
     ]
    }
   ],
   "source": [
    "sourcefile=open(jsonfile,'rU')\n",
    "infos=json.load(sourcefile)\n",
    "nb_profilesEN4=len(infos)\n",
    "\n",
    "print(time.strftime('%d/%m/%y %H:%M',time.localtime()))\n",
    "\n",
    "dsN,latN,lonN,timN = open_gs36()\n",
    "\n",
    "print(time.strftime('%d/%m/%y %H:%M',time.localtime()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/12/19 14:13\n",
      "Processing profile  b' A20121001-03173'\n",
      "selected profile falls within GS36 boundaries, the program is proceeding\n",
      "output file is /scratch/cnt0024/hmg2840/albert7a/EN4/profiles_files/NATL60-CJM165_GS_y2012-2013/profiles_EN4-' A20121001-03173'_NATL60-CJM165_TS.nc\n",
      "19/12/19 14:15\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime('%d/%m/%y %H:%M',time.localtime()))\n",
    "prof=0\n",
    "process(jsonfile,infos,prof,dsN,latN,lonN,timN)\n",
    "print(time.strftime('%d/%m/%y %H:%M',time.localtime()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for prof in np.arange(nb_profilesEN4):\n",
    "    process(jsonfile,infos,prof,dsN,latN,lonN,timN)\n",
    "\n",
    "print time.strftime('%d/%m/%y %H:%M',time.localtime())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
