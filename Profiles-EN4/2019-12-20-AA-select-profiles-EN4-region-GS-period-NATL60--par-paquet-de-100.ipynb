{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce the json file listing all profiles in GS region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dask\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import glob as glob\n",
    "import time\n",
    "from datetime import date\n",
    "import io\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "latmin,latmax,lonmin,lonmax=(27,48,-81,-40)\n",
    "datemin,datemax=('2012-10-01','2013-09-30')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EN.4.2.0.f.profiles.g10.201210.nc', 'EN.4.2.0.f.profiles.g10.201211.nc', 'EN.4.2.0.f.profiles.g10.201212.nc', 'EN.4.2.0.f.profiles.g10.201301.nc', 'EN.4.2.0.f.profiles.g10.201302.nc', 'EN.4.2.0.f.profiles.g10.201303.nc', 'EN.4.2.0.f.profiles.g10.201304.nc', 'EN.4.2.0.f.profiles.g10.201305.nc', 'EN.4.2.0.f.profiles.g10.201306.nc', 'EN.4.2.0.f.profiles.g10.201307.nc', 'EN.4.2.0.f.profiles.g10.201308.nc', 'EN.4.2.0.f.profiles.g10.201309.nc']\n"
     ]
    }
   ],
   "source": [
    "        ''' Identify all the EN4 profiles that fall within the selected zone and period\n",
    "        '''\n",
    "        ## Datasets\n",
    "\n",
    "        #EN4\n",
    "        diren4=\"/scratch/cnt0024/hmg2840/albert7a/EN4/\"\n",
    "\n",
    "        yearmin=datemin[0:4]\n",
    "        monthmin=datemin[5:7]\n",
    "        yearmax=datemax[0:4]\n",
    "        monthmax=datemax[5:7]\n",
    "\n",
    "        list_filesEN4=[]\n",
    "        if yearmin == yearmax:\n",
    "            for m in np.arange(int(monthmin),int(monthmax)+1):\n",
    "                if m < 10:\n",
    "                    list_filesEN4.append('EN.4.2.0.f.profiles.g10.'+yearmin+'0'+str(m)+'.nc')\n",
    "                else:\n",
    "                    list_filesEN4.append('EN.4.2.0.f.profiles.g10.'+yearmin+str(m)+'.nc')\n",
    "        else:\n",
    "            for m in np.arange(int(monthmin),13):\n",
    "                if m < 10:\n",
    "                    list_filesEN4.append('EN.4.2.0.f.profiles.g10.'+yearmin+'0'+str(m)+'.nc')\n",
    "                else:\n",
    "                    list_filesEN4.append('EN.4.2.0.f.profiles.g10.'+yearmin+str(m)+'.nc')\n",
    "        if int(yearmin)+1 == int(yearmax):\n",
    "            for m in np.arange(1,int(monthmax)+1):\n",
    "                if m < 10:\n",
    "                    list_filesEN4.append('EN.4.2.0.f.profiles.g10.'+yearmax+'0'+str(m)+'.nc')\n",
    "                else:\n",
    "                    list_filesEN4.append('EN.4.2.0.f.profiles.g10.'+yearmax+str(m)+'.nc')\n",
    "        else:\n",
    "            for year in np.arange(int(yearmin)+1,int(yearmax)):\n",
    "                for m in np.arange(1,13):\n",
    "                    if m < 10:\n",
    "                        list_filesEN4.append('EN.4.2.0.f.profiles.g10.'+str(year)+'0'+str(m)+'.nc')\n",
    "                    else:\n",
    "                        list_filesEN4.append('EN.4.2.0.f.profiles.g10.'+str(year)+str(m)+'.nc')\n",
    "        print(list_filesEN4)\n",
    "\n",
    "        datetmin=pd.to_datetime(datemin)\n",
    "        datetmax=pd.to_datetime(datemax)\n",
    "        ttmin=datetime.datetime(int(datetmin.strftime('%Y')),int(datetmin.strftime('%m')),int(datetmin.strftime('%d')),int(datetmin.strftime('%H')),int(datetmin.strftime('%M')))\n",
    "        ttmax=datetime.datetime(int(datetmax.strftime('%Y')),int(datetmax.strftime('%m')),int(datetmax.strftime('%d')),int(datetmax.strftime('%H')),int(datetmax.strftime('%M')))\n",
    "        tsecmin=(ttmin-datetime.datetime(1958,1,1,0,0)).total_seconds()\n",
    "        tsecmax=(ttmax-datetime.datetime(1958,1,1,0,0)).total_seconds()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing EN.4.2.0.f.profiles.g10.201210.nc\n",
      "Processing EN.4.2.0.f.profiles.g10.201211.nc\n",
      "Processing EN.4.2.0.f.profiles.g10.201212.nc\n",
      "Processing EN.4.2.0.f.profiles.g10.201301.nc\n",
      "Processing EN.4.2.0.f.profiles.g10.201302.nc\n",
      "Processing EN.4.2.0.f.profiles.g10.201303.nc\n",
      "Processing EN.4.2.0.f.profiles.g10.201304.nc\n",
      "Processing EN.4.2.0.f.profiles.g10.201305.nc\n",
      "Processing EN.4.2.0.f.profiles.g10.201306.nc\n",
      "Processing EN.4.2.0.f.profiles.g10.201307.nc\n",
      "Processing EN.4.2.0.f.profiles.g10.201308.nc\n",
      "Processing EN.4.2.0.f.profiles.g10.201309.nc\n"
     ]
    }
   ],
   "source": [
    "        nb=0\n",
    "        for f in np.arange(len(list_filesEN4)):\n",
    "            fileEN4=list_filesEN4[f]\n",
    "            print('Processing '+str(fileEN4))\n",
    "            tfileEN4=diren4+fileEN4\n",
    "            dsen4=xr.open_dataset(tfileEN4)\n",
    "            laten4=dsen4['LATITUDE']\n",
    "            lonen4=dsen4['LONGITUDE']\n",
    "            dayen4=dsen4['JULD']\n",
    "            refen4=dsen4['DC_REFERENCE']\n",
    "            indz=np.where((lonmin<lonen4.values)&(lonen4.values<lonmax)&(latmin<laten4.values)&(laten4.values<latmax))\n",
    "            prof_zone=[]\n",
    "            tsecen4z=[]\n",
    "        for ref in np.arange(len(indz[0])):\n",
    "                dateen4= pd.to_datetime(str(dayen4[indz[0][ref]].values))\n",
    "                ten4 = datetime.datetime(int(dateen4.strftime('%Y')),int(dateen4.strftime('%m')),int(dateen4.strftime('%d')),int(dateen4.strftime('%H')),int(dateen4.strftime('%M')))\n",
    "                tsecen4=(ten4-datetime.datetime(1958,1,1,0,0)).total_seconds()\n",
    "                if (tsecen4 < tsecmax) & (tsecen4 > tsecmin):\n",
    "                    prof_zone.append(indz[0][ref])\n",
    "                    tsecen4z.append(tsecen4)\n",
    "        for ref in np.arange(len(prof_zone)):\n",
    "                nb=nb+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19282\n"
     ]
    }
   ],
   "source": [
    "print(nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                if 'dictyml' in locals():\n",
    "                    up={str(refen4[prof_zone[ref]].values):{'reference':str(refen4[prof_zone[ref]].values),'file':fileEN4,'profile no':int(prof_zone[ref]),'latitude':float(laten4[prof_zone[ref]].values),'longitude':float(lonen4[prof_zone[ref]].values),'date':str(dayen4[prof_zone[ref]].values)}}\n",
    "                    dictyml.update(up)\n",
    "                else:\n",
    "                    dictyml={str(refen4[prof_zone[ref]].values):{'reference':str(refen4[prof_zone[ref]].values),'file':fileEN4,'profile no':int(prof_zone[ref]),'latitude':float(laten4[prof_zone[ref]].values),'longitude':float(lonen4[prof_zone[ref]].values),'date':str(dayen4[prof_zone[ref]].values)}}\n",
    "                    \n",
    "        with io.open(jsonfile, 'w', encoding='utf8') as outfile:\n",
    "            outfile.write(str(json.dumps(dictyml, sort_keys=True,indent=4, separators=(',', ': '))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
