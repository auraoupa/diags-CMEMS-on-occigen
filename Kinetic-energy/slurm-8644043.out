/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:43242'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:41806'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:45274'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:33702'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:38881'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:45723'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:36642'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:40201'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:34498'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:35997'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:42157'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:35744'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:38557'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:45446'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:42993'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:38090'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:39927'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:45481'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:46451'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:45848'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:33974'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:38866'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:34081'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:46506'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:36966'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:36468'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:34958'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.6.172:39664'
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:35789
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:35789
distributed.worker - INFO -              nanny at:         172.30.6.172:38881
distributed.worker - INFO -              bokeh at:         172.30.6.172:42632
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-41sq23zj
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:34661
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:34661
distributed.worker - INFO -              nanny at:         172.30.6.172:45446
distributed.worker - INFO -              bokeh at:         172.30.6.172:44589
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-v41t8xnv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:38792
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:38792
distributed.worker - INFO -              nanny at:         172.30.6.172:42993
distributed.worker - INFO -              bokeh at:         172.30.6.172:37527
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-1nf5okoa
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:33175
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:33175
distributed.worker - INFO -              nanny at:         172.30.6.172:40201
distributed.worker - INFO -              bokeh at:         172.30.6.172:34090
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ff41nglo
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:33998
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:33998
distributed.worker - INFO -              nanny at:         172.30.6.172:36966
distributed.worker - INFO -              bokeh at:         172.30.6.172:39354
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0t3ol6h3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:34172
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:34172
distributed.worker - INFO -              nanny at:         172.30.6.172:34498
distributed.worker - INFO -              bokeh at:         172.30.6.172:33428
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-oqc_8d6x
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:45050
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:45050
distributed.worker - INFO -              nanny at:         172.30.6.172:34958
distributed.worker - INFO -              bokeh at:         172.30.6.172:32886
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-grvjvot0
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:42072
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:42072
distributed.worker - INFO -              nanny at:         172.30.6.172:38090
distributed.worker - INFO -              bokeh at:         172.30.6.172:43277
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-o9qrginm
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:34294
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:34294
distributed.worker - INFO -              nanny at:         172.30.6.172:41806
distributed.worker - INFO -              bokeh at:         172.30.6.172:43404
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:43670
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:43670
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -              nanny at:         172.30.6.172:46451
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-e21x12d1
distributed.worker - INFO -              bokeh at:         172.30.6.172:46537
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6ou8rfsh
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:41975
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:41975
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:34622
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:34622
distributed.worker - INFO -              nanny at:         172.30.6.172:35744
distributed.worker - INFO -              bokeh at:         172.30.6.172:37734
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO -              nanny at:         172.30.6.172:36642
distributed.worker - INFO -              bokeh at:         172.30.6.172:34811
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-r9rkzo6r
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-dr25n5t6
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:35277
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:35277
distributed.worker - INFO -              nanny at:         172.30.6.172:38866
distributed.worker - INFO -              bokeh at:         172.30.6.172:40050
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-42vxl55g
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:37333
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:37333
distributed.worker - INFO -              nanny at:         172.30.6.172:46506
distributed.worker - INFO -              bokeh at:         172.30.6.172:33018
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-nxx0ta58
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:44030
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:44030
distributed.worker - INFO -              nanny at:         172.30.6.172:35997
distributed.worker - INFO -              bokeh at:         172.30.6.172:33856
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-l_mm7w57
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:36119
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:36119
distributed.worker - INFO -              nanny at:         172.30.6.172:45848
distributed.worker - INFO -              bokeh at:         172.30.6.172:38861
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-h398c74q
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:39925
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:39925
distributed.worker - INFO -              nanny at:         172.30.6.172:39927
distributed.worker - INFO -              bokeh at:         172.30.6.172:45208
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-yu387s_e
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:44833
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:44833
distributed.worker - INFO -              nanny at:         172.30.6.172:33974
distributed.worker - INFO -              bokeh at:         172.30.6.172:36418
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ef0xcdd7
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:45027
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:45027
distributed.worker - INFO -              nanny at:         172.30.6.172:34081
distributed.worker - INFO -              bokeh at:         172.30.6.172:39277
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-2fr5ylou
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:45747
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:45747
distributed.worker - INFO -              nanny at:         172.30.6.172:43242
distributed.worker - INFO -              bokeh at:         172.30.6.172:41922
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-px48wu5s
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:37327
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:37327
distributed.worker - INFO -              nanny at:         172.30.6.172:39664
distributed.worker - INFO -              bokeh at:         172.30.6.172:41654
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-4esqsfrq
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:37357
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:37357
distributed.worker - INFO -              nanny at:         172.30.6.172:45723
distributed.worker - INFO -              bokeh at:         172.30.6.172:39003
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-5zfo4dah
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:36331
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:36331
distributed.worker - INFO -              nanny at:         172.30.6.172:33702
distributed.worker - INFO -              bokeh at:         172.30.6.172:39400
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-fqk_mkd5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:46708
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:46708
distributed.worker - INFO -              nanny at:         172.30.6.172:36468
distributed.worker - INFO -              bokeh at:         172.30.6.172:45212
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-zex3oi86
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:38376
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:38376
distributed.worker - INFO -              nanny at:         172.30.6.172:45481
distributed.worker - INFO -              bokeh at:         172.30.6.172:35919
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:40202
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:40202
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -              nanny at:         172.30.6.172:45274
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0iaut3pg
distributed.worker - INFO -              bokeh at:         172.30.6.172:46645
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ihueh5n7
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:44595
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:44595
distributed.worker - INFO -              nanny at:         172.30.6.172:38557
distributed.worker - INFO -              bokeh at:         172.30.6.172:35416
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-1stj21q8
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.6.172:40203
distributed.worker - INFO -          Listening to:   tcp://172.30.6.172:40203
distributed.worker - INFO -              nanny at:         172.30.6.172:42157
distributed.worker - INFO -              bokeh at:         172.30.6.172:35665
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-24suv2nu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.utils_perf - INFO - full garbage collection released 15.25 MB from 142 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.utils_perf - INFO - full garbage collection released 15.47 MB from 122 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.utils_perf - INFO - full garbage collection released 15.46 MB from 285 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.utils_perf - INFO - full garbage collection released 15.45 MB from 188 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50180 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50184 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50176 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50272 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50264 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50338 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50364 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50414 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50204 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50256 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50390 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50430 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50166 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50332 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50358 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50188 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50244 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50304 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50342 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50453 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50126 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50174 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50228 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50394 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50436 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50122 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50170 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50226 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50282 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50350 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50134 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50294 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50426 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50158 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50216 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50146 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50196 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50252 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50308 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50354 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50138 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50186 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50298 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50266 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50418 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50208 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50320 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50932 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50362 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50140 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50192 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50248 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50302 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50408 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50258 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50938 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50410 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50260 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50940 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50382 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50428 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50160 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50218 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50956 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50388 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50432 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50164 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50334 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50962 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50336 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50392 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50434 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50120 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50168 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50224 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50280 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50966 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50274 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50424 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50162 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50954 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50340 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50452 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50124 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50172 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50230 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50178 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50346 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50132 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51014 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50422 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50154 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50211 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50318 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50946 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51028 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50356 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50144 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50194 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50250 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50306 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50934 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50344 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50456 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50128 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50232 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50970 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50182 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50348 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50130 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51016 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50412 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50148 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50944 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50262 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50420 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50152 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50210 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50322 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50948 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51030 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50360 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50142 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50246 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50300 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50928 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50268 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50416 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50156 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50206 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50324 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50952 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51034 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50352 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50136 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50296 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50942 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50960 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50930 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51018 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50964 remote=tcp://172.30.100.2:42270>
distributed.utils_perf - INFO - full garbage collection released 44.28 MB from 423 reference cycles (threshold: 10.00 MB)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50936 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50968 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50958 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:50950 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51032 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51372 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51366 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51356 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51370 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51442 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51376 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51440 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51444 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51450 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51358 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51446 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.6.172:51351 remote=tcp://172.30.100.2:42270>
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:44030
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:46708
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:35277
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:34622
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:35997'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:36468'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:38866'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:43670
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:36642'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:46451'
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:35789
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:38881'
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:40203
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:42157'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:40202
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:45050
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:45274'
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:34958'
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:41975
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:42072
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:35744'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:38090'
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:45747
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:44833
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:45027
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:43242'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:33974'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:37333
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:34081'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:37327
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:46506'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:33175
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:39664'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:40201'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:44595
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:38792
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:38557'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:42993'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:36331
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:37357
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:33702'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:34294
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:36119
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:45723'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:33998
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:45848'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:41806'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:36966'
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:38376
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:45481'
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:34172
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:34498'
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:34661
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:45446'
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Stopping worker at tcp://172.30.6.172:39925
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.6.172:39927'
distributed.dask_worker - INFO - End worker
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
