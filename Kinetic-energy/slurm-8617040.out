/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:40083'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:42253'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:36123'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:42911'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:33418'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:39318'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:42607'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:44818'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:37388'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:42153'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:40360'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:44590'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:36498'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:46351'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:33955'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:35854'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:39072'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:45250'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:46275'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:37914'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:41769'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:45010'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:46793'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:35719'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:36701'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:35017'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:40545'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.9.124:42359'
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xomg8np6', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_3axwqy2', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-lt0qsocm', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-brm66yui', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-2jaoi8gm', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:33956
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:41696
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:35348
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:42204
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:33720
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:46608
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:43023
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:37335
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:41459
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:33956
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:41696
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:35348
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:34667
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:42204
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:33720
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:46608
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:43023
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:37335
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:41459
distributed.worker - INFO -              nanny at:         172.30.9.124:36701
distributed.worker - INFO -              nanny at:         172.30.9.124:46351
distributed.worker - INFO -              nanny at:         172.30.9.124:33418
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:34667
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:45368
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:43986
distributed.worker - INFO -              nanny at:         172.30.9.124:44590
distributed.worker - INFO -              nanny at:         172.30.9.124:40083
distributed.worker - INFO -              nanny at:         172.30.9.124:33955
distributed.worker - INFO -              nanny at:         172.30.9.124:39318
distributed.worker - INFO -              nanny at:         172.30.9.124:35017
distributed.worker - INFO -              nanny at:         172.30.9.124:42153
distributed.worker - INFO -              bokeh at:         172.30.9.124:35776
distributed.worker - INFO -              bokeh at:         172.30.9.124:35496
distributed.worker - INFO -              bokeh at:         172.30.9.124:44457
distributed.worker - INFO -              nanny at:         172.30.9.124:35854
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:45368
distributed.worker - INFO -              bokeh at:         172.30.9.124:40615
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:43986
distributed.worker - INFO -              bokeh at:         172.30.9.124:38675
distributed.worker - INFO -              bokeh at:         172.30.9.124:39872
distributed.worker - INFO -              bokeh at:         172.30.9.124:45080
distributed.worker - INFO -              bokeh at:         172.30.9.124:45232
distributed.worker - INFO -              bokeh at:         172.30.9.124:37884
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO -              bokeh at:         172.30.9.124:43042
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO -              nanny at:         172.30.9.124:37914
distributed.worker - INFO -              nanny at:         172.30.9.124:46793
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO -              bokeh at:         172.30.9.124:32996
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -              bokeh at:         172.30.9.124:44364
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-7kmlf9kr
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-mdwrgybb
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-e6rkdmiu
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-c2t3nv_9
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-e1q0l0nc
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-4cat45m3
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-p71i6x5r
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-45y96gt6
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-o9q5dz0o
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ehbqw5pe
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-mqtq9a_9
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-di2pshg5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:46280
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:46280
distributed.worker - INFO -              nanny at:         172.30.9.124:42359
distributed.worker - INFO -              bokeh at:         172.30.9.124:38501
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-7pddmo04
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-rszc9s4d', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-7q96nl53', purging
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-e1jj4jhy', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-fn_3lgt4', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-r6bfdtdk', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xqimqfbr', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-enkap91v', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-75o5cf1x', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:41214
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:41214
distributed.worker - INFO -              nanny at:         172.30.9.124:45250
distributed.worker - INFO -              bokeh at:         172.30.9.124:39163
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xl6lfm8d
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-evur8wq2', purging
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:35670
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:35670
distributed.worker - INFO -              nanny at:         172.30.9.124:41769
distributed.worker - INFO -              bokeh at:         172.30.9.124:36791
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-lulh9xop
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:39232
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:39232
distributed.worker - INFO -              nanny at:         172.30.9.124:44818
distributed.worker - INFO -              bokeh at:         172.30.9.124:46659
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-blh4yp_g
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-la_n755u', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:40274
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:40274
distributed.worker - INFO -              nanny at:         172.30.9.124:40545
distributed.worker - INFO -              bokeh at:         172.30.9.124:39954
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-2xysbh4z
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:38343
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:38343
distributed.worker - INFO -              nanny at:         172.30.9.124:42911
distributed.worker - INFO -              bokeh at:         172.30.9.124:44527
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-i3_02ei5
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-mka3v6ud', purging
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:40126
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:40126
distributed.worker - INFO -              nanny at:         172.30.9.124:39072
distributed.worker - INFO -              bokeh at:         172.30.9.124:41884
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ftwacmuw
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:36013
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:36013
distributed.worker - INFO -              nanny at:         172.30.9.124:45010
distributed.worker - INFO -              bokeh at:         172.30.9.124:40888
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-eqikwa5s
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-56zsg3dj', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jw8piiy8', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:34870
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:34870
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:41839
distributed.worker - INFO -              nanny at:         172.30.9.124:42607
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:41839
distributed.worker - INFO -              bokeh at:         172.30.9.124:46306
distributed.worker - INFO -              nanny at:         172.30.9.124:37388
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO -              bokeh at:         172.30.9.124:43898
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-7gpvnw0m
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-49_23e8m
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:38214
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:38214
distributed.worker - INFO -              nanny at:         172.30.9.124:36123
distributed.worker - INFO -              bokeh at:         172.30.9.124:44503
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ozyvk8x_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_ecy5_ew', purging
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-s8hh_ya9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_jswv_gj', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-3czwhdv6', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:36529
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:36529
distributed.worker - INFO -              nanny at:         172.30.9.124:36498
distributed.worker - INFO -              bokeh at:         172.30.9.124:35322
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-j9el58gn
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:46808
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:46808
distributed.worker - INFO -              nanny at:         172.30.9.124:46275
distributed.worker - INFO -              bokeh at:         172.30.9.124:38641
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-lpjpsgma
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-it3up1vy', purging
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-h9muhj8c', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-v95cbs7_', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:36356
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:36356
distributed.worker - INFO -              nanny at:         172.30.9.124:40360
distributed.worker - INFO -              bokeh at:         172.30.9.124:45623
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-v6q2v58i
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_3cg40lv', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-tb99vje5', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-g6t1gzvo', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-e__36728', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-no8l3qoi', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-hesy26je', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-mui45xy5', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0z8xj363', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-5kmdhigy', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8b5gpmjo', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-v_xohaz0', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-gbbgqh3o', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-zwkg6lxg', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6wuqyiox', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-7ewyrt1b', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-na1q05uz', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-v59xtm63', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-v1lf8hq3', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-a46mq62x', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-woob1qux', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-a3907ci6', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:35747
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:35747
distributed.worker - INFO -              nanny at:         172.30.9.124:35719
distributed.worker - INFO -              bokeh at:         172.30.9.124:39058
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-3ikx4_ly
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-b60exk70', purging
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vt6p_wv1', purging
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-g21paxi1', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6cexjk7a', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-e69ub2cp', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vaixft4z', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vud21xps', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-j1nfftj_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-fgvf0_nf', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xwl6vq6z', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-aibkjuiw', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ckq0htgj', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6frin9t4', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-3eaqkf8k', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_25mzkgd', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-12b5yr37', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0rem7hbo', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-dfjhzfjr', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8m46rfp_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-1mc5e9dg', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-zf8zzmaq', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-bq5o7sco', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-nt9e10pi', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-z0j1dl9m', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-9cp226_2', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-9h3s89h8', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-uufd4efu', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-npv3zxxf', purging
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0lbvh29k', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vabeumth', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-hle9lx3l', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vktlgh9f', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-cnr7hgfl', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-spal33sy', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ez6y3yqn', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-3rtryl32', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-02t64_z7', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-7ufs5cic', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8wrq7t4x', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jd02pwq2', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-22pebo63', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-pbxl5f41', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-1g08whkz', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-y8vrud8u', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-j0w4e7f1', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8zqbcsli', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-b433bwux', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-blw49o7_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-n6hums7f', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ol_i9s4_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-27z_amnj', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-l7lcz8nd', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vvvpun_1', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ac77f5mf', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0mhe6o1s', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xmhn32_f', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-rxfowp9q', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-sits7uze', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ddomzfj8', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-y2p30czt', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-b0qxt1ff', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.9.124:42131
distributed.worker - INFO -          Listening to:   tcp://172.30.9.124:42131
distributed.worker - INFO -              nanny at:         172.30.9.124:42253
distributed.worker - INFO -              bokeh at:         172.30.9.124:43366
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-182m4fpa
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:44717
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.core - INFO - Event loop was unresponsive in Worker for 11.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.utils_perf - INFO - full garbage collection released 61.43 MB from 668 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40138 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40136 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40134 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40250 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x2b1b9a720c50>>, <Future finished exception=OSError("Timed out trying to connect to 'tcp://172.30.100.2:44717' after 10 s: connect() didn't finish in time")>)
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 218, in connect
    quiet_exceptions=EnvironmentError,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
tornado.util.TimeoutError: Timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py", line 743, in _run_callback
    ret = callback()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py", line 767, in _discard_future_result
    future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 748, in heartbeat
    address=self.contact_address, now=time(), metrics=self.get_metrics()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/core.py", line 736, in send_recv_from_rpc
    comm = yield self.pool.connect(self.addr)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/core.py", line 864, in connect
    connection_args=self.connection_args,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 230, in connect
    _raise(error)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 207, in _raise
    raise IOError(msg)
OSError: Timed out trying to connect to 'tcp://172.30.100.2:44717' after 10 s: connect() didn't finish in time
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40254 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40102 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40140 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40258 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40106 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40142 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40180 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40296 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40218 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40120 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40196 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40270 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40586 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40252 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40594 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40264 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40110 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40148 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40248 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40100 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40262 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40108 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40146 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40162 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40198 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40275 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40124 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40238 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40588 remote=tcp://172.30.100.2:44717>
distributed.utils_perf - INFO - full garbage collection released 48.43 MB from 647 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40114 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40154 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40192 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40228 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40268 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40116 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40190 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40230 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40266 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40122 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40202 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40276 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40158 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40584 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40284 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40256 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40104 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40144 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40294 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40220 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40574 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40272 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40118 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40160 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40568 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40580 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40244 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40282 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40206 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40592 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40260 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40150 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40164 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40200 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40278 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40127 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40240 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40582 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40242 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40280 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40318 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40128 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40204 remote=tcp://172.30.100.2:44717>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.9.124:40590 remote=tcp://172.30.100.2:44717>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:44717
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:46808
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:38343
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:39232
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:36356
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:45368
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:43986
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:46280
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:33956
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:34667
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:36013
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:35747
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:40126
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:41839
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:46275'
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:34870
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:36529
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:40360'
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:43023
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:42911'
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:41696
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:35670
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:46793'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:44818'
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:38214
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:35348
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:42204
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:40274
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:46608
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:41459
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:41214
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:33720
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:37335
distributed.worker - INFO - Stopping worker at tcp://172.30.9.124:42131
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:42359'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:36701'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:35719'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:35854'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:39072'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:45010'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:37388'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:36498'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:42607'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:39318'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:46351'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:41769'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:44590'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:45250'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:33418'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:36123'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:33955'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:40545'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:42153'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:40083'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:35017'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:42253'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.9.124:37914'
distributed.dask_worker - INFO - End worker
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
