/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:40369'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:39926'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:43331'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:35510'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:46326'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:37962'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:37446'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:46666'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:37796'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:41068'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:40116'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:36545'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:35174'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:40936'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:44086'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:35839'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:38860'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:45147'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:41984'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:36804'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:45425'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:42851'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:35720'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:42928'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:46670'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:38400'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:44281'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.8.161:46551'
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:46775
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:34789
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:37243
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:40299
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:46775
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:46864
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:34789
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:37243
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:40299
distributed.worker - INFO -              nanny at:         172.30.8.161:40369
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:46864
distributed.worker - INFO -              nanny at:         172.30.8.161:41068
distributed.worker - INFO -              nanny at:         172.30.8.161:35839
distributed.worker - INFO -              nanny at:         172.30.8.161:35174
distributed.worker - INFO -              bokeh at:         172.30.8.161:37454
distributed.worker - INFO -              nanny at:         172.30.8.161:37446
distributed.worker - INFO -              bokeh at:         172.30.8.161:46063
distributed.worker - INFO -              bokeh at:         172.30.8.161:41977
distributed.worker - INFO -              bokeh at:         172.30.8.161:44443
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO -              bokeh at:         172.30.8.161:43151
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0alxdgfq
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-nindveok
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-rjowac79
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-zjmsnyvu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-y5jvzjel
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:37166
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:37166
distributed.worker - INFO -              nanny at:         172.30.8.161:46670
distributed.worker - INFO -              bokeh at:         172.30.8.161:44075
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-slyxy4ag
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:44469
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:44469
distributed.worker - INFO -              nanny at:         172.30.8.161:38860
distributed.worker - INFO -              bokeh at:         172.30.8.161:46030
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ddw0spgo
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:40370
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:41569
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:40370
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:41569
distributed.worker - INFO -              nanny at:         172.30.8.161:44086
distributed.worker - INFO -              nanny at:         172.30.8.161:40936
distributed.worker - INFO -              bokeh at:         172.30.8.161:44022
distributed.worker - INFO -              bokeh at:         172.30.8.161:38332
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8qan4qpg
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-t2ijqctz
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:43960
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:43960
distributed.worker - INFO -              nanny at:         172.30.8.161:46666
distributed.worker - INFO -              bokeh at:         172.30.8.161:37296
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-q0n2lz0h
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:46605
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:46605
distributed.worker - INFO -              nanny at:         172.30.8.161:36545
distributed.worker - INFO -              bokeh at:         172.30.8.161:42395
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-i3_mn39o
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:34788
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:34788
distributed.worker - INFO -              nanny at:         172.30.8.161:37962
distributed.worker - INFO -              bokeh at:         172.30.8.161:46112
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:41775
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:41775
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-oz10833w
distributed.worker - INFO -              nanny at:         172.30.8.161:35510
distributed.worker - INFO -              bokeh at:         172.30.8.161:44438
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-m5rp39mk
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:38355
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:38355
distributed.worker - INFO -              nanny at:         172.30.8.161:46326
distributed.worker - INFO -              bokeh at:         172.30.8.161:39483
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:42458
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-kdmegztz
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:42458
distributed.worker - INFO -              nanny at:         172.30.8.161:37796
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -              bokeh at:         172.30.8.161:34038
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-uruute1f
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:41872
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:41872
distributed.worker - INFO -              nanny at:         172.30.8.161:42928
distributed.worker - INFO -              bokeh at:         172.30.8.161:35579
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-y73k0tie
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:35308
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:35308
distributed.worker - INFO -              nanny at:         172.30.8.161:42851
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:33665
distributed.worker - INFO -              bokeh at:         172.30.8.161:43293
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:33665
distributed.worker - INFO -              nanny at:         172.30.8.161:41984
distributed.worker - INFO -              bokeh at:         172.30.8.161:41790
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vin3zza0
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8ziphc6m
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:45885
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:45885
distributed.worker - INFO -              nanny at:         172.30.8.161:45147
distributed.worker - INFO -              bokeh at:         172.30.8.161:46286
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-dfvbcyrq
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:45315
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:37118
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:45315
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:37118
distributed.worker - INFO -              nanny at:         172.30.8.161:38400
distributed.worker - INFO -              bokeh at:         172.30.8.161:37758
distributed.worker - INFO -              nanny at:         172.30.8.161:36804
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO -              bokeh at:         172.30.8.161:37316
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-f93p0eub
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-mkqug2g2
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:45333
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:45333
distributed.worker - INFO -              nanny at:         172.30.8.161:43331
distributed.worker - INFO -              bokeh at:         172.30.8.161:34342
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-mg4tas2x
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:36494
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:36494
distributed.worker - INFO -              nanny at:         172.30.8.161:45425
distributed.worker - INFO -              bokeh at:         172.30.8.161:43815
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xbz4qcfk
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:42826
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:42826
distributed.worker - INFO -              nanny at:         172.30.8.161:40116
distributed.worker - INFO -              bokeh at:         172.30.8.161:34298
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:35009
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:35009
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jy2hb348
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -              nanny at:         172.30.8.161:39926
distributed.worker - INFO -              bokeh at:         172.30.8.161:43235
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-pm3kp5nf
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:37587
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:37587
distributed.worker - INFO -              nanny at:         172.30.8.161:46551
distributed.worker - INFO -              bokeh at:         172.30.8.161:46748
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-y3dcz1sz
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:37873
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:37873
distributed.worker - INFO -              nanny at:         172.30.8.161:35720
distributed.worker - INFO -              bokeh at:         172.30.8.161:46358
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-tqoh5wue
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.8.161:36734
distributed.worker - INFO -          Listening to:   tcp://172.30.8.161:36734
distributed.worker - INFO -              nanny at:         172.30.8.161:44281
distributed.worker - INFO -              bokeh at:         172.30.8.161:45007
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-h0gn9906
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO -         Registered to:   tcp://172.30.100.2:42270
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.utils_perf - INFO - full garbage collection released 15.43 MB from 174 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39666 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39594 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39732 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39668 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39762 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39744 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39596 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39760 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39750 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39866 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39592 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39696 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39730 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39786 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39826 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39598 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39558 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39708 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39748 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39860 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39548 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39580 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39670 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39726 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39820 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39738 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39792 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39828 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39578 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39624 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39680 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39736 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39790 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39830 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39576 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39678 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40198 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40184 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40188 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39754 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39864 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39590 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39694 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39644 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40234 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40288 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39812 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39564 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40202 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39600 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39764 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39872 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39706 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39652 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39862 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39546 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39584 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39636 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40182 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40230 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40286 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39746 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39858 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39582 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39632 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40180 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40228 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40282 remote=tcp://172.30.100.2:42270>
distributed.utils_perf - INFO - full garbage collection released 24.12 MB from 816 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39752 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39868 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39550 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39588 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39698 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39638 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40236 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39788 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39824 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40216 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39734 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39794 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39832 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39626 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39682 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40220 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39740 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39796 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39684 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39628 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40176 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40224 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39756 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39870 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39552 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39586 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39700 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39640 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39556 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39704 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39776 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39818 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39570 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39722 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40206 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39728 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39784 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39822 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39574 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39618 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39672 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40212 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39742 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39544 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40178 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40226 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40280 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39806 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39758 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39554 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39702 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39654 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39770 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39804 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40196 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39808 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39560 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39780 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39816 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39572 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39724 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40208 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39778 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39814 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39568 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39720 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40204 remote=tcp://172.30.100.2:42270>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39566 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39810 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40200 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39642 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40186 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40238 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40290 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40214 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39634 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40232 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40284 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:39650 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40210 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40222 remote=tcp://172.30.100.2:42270>
distributed.utils_perf - INFO - full garbage collection released 57.55 MB from 518 reference cycles (threshold: 10.00 MB)
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40218 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40700 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40680 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40696 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40626 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40682 remote=tcp://172.30.100.2:42270>
distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://172.30.8.161:40688 remote=tcp://172.30.100.2:42270>
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:34788
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:37962'
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:38355
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:46326'
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:37166
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:46670'
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:36494
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:37118
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:37243
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:41775
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:46864
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:45425'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:38400'
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:35839'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:35510'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:37446'
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:37873
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:35720'
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:33665
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:45315
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:41984'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:36804'
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:40370
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:34789
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:41068'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:44086'
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:45885
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:45147'
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:42826
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:40116'
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:36734
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:37587
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:44281'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:46551'
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:35009
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:39926'
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:42458
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:41569
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:40936'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:37796'
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:44469
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:38860'
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:46605
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:35308
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:46775
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:41872
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:42851'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:36545'
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:43960
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:40369'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:42928'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:46666'
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.2:42270
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:45333
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:43331'
distributed.worker - INFO - Stopping worker at tcp://172.30.8.161:40299
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.8.161:35174'
distributed.dask_worker - INFO - End worker
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
